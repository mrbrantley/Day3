{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCWxl5KKRUSN"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "* About Pytorch\n",
    "* Tensors\n",
    "* Autograd\n",
    "* Building a model\n",
    "* Loading data\n",
    "* Training\n",
    "\n",
    "\n",
    "## Installing Pytorch here...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13464,
     "status": "ok",
     "timestamp": 1729626805751,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "8-EhWFwjR7Ko",
    "outputId": "08d2b56a-6b73-48c1-85ac-ca2bf99af10b"
   },
   "source": [
    "%pip install torch torchvision"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKWBQFFoR9_z"
   },
   "source": [
    "And then to use it in your python code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6353,
     "status": "ok",
     "timestamp": 1729630313991,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "Hi0ZEkJjSBjk",
    "outputId": "5d7dae0b-8bfd-4f47-81b8-0f1197c83b6a"
   },
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoLR45xNSMdp"
   },
   "source": [
    "## What is PyTorch?\n",
    "\n",
    "An open source ML framework in Python that accerlates path from prototyping to deplyment. It integrates with just about every other framework.  \n",
    "\n",
    "Pytorch has lots of tools NN layer types, activation and loss functions, optimizers, and a \"vision\" add-on if you want to do machine vision.\n",
    "\n",
    "PyTorch offers more than 300 functions for doing associated operations.\n",
    "\n",
    "## What is a Tensor?\n",
    "\n",
    "It's just a \"multi-dimensional array\", and a universal standard for storing data for uses in ML.  Since we've played with Python and NumPy, you already have a pretty good idea.  You access thes tensors through python API, but actually runs highly optimized C++ code."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729630313991,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "dWfXh1mMUG53",
    "outputId": "df3da30f-4351-4b9f-e025-bfc2484fcaf7"
   },
   "source": [
    "# make a tensor with 5rows, and 3 columns, and inspect it...\n",
    "theZeros = torch.zeros(5, 3)\n",
    "print(theZeros)\n",
    "print(theZeros.dtype)  #notices it's a matrix of 32bit floats"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDgLCPFMUgdk"
   },
   "source": [
    "But you can make a collection of integers if you prefer, but we usually use floats."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1729630315425,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "rXbW0-nZUwOj",
    "outputId": "f9884ccb-c30a-4fba-e93a-8b2948b40c07"
   },
   "source": [
    "i = torch.ones((5, 3), dtype=torch.int16)\n",
    "print(i)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W34wot7U7VN"
   },
   "source": [
    "Ok -- let's make a small tensor and fill it with random data. Now, let's do some operations on it.\n",
    "\n",
    "With tensors, we can apply basic scalar operations across all values. We can add, subtract, multiply.  We can get absolute values, apply trigonometric operations, statistical operations, and lots more."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1729630317767,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "afOODWhJU_lF",
    "outputId": "73a2e91b-8838-4276-eb57-bf877bae7721"
   },
   "source": [
    "torch.manual_seed(1729) #rerun this, and you'll restart the random sequence\n",
    "r1 = torch.rand(2, 2)\n",
    "print('A random tensor:')\n",
    "print(r1)\n",
    "\n",
    "r = torch.rand(2, 2) - 0.5 * 2 # values between -1 and 1\n",
    "print('A random matrix, r:')\n",
    "print(r)\n",
    "\n",
    "# Common mathematical operations are supported:\n",
    "print('\\nAbsolute value of r:')\n",
    "print(torch.abs(r))\n",
    "\n",
    "# ...as are trigonometric functions:\n",
    "print('\\nInverse sine of r:')\n",
    "print(torch.asin(r))\n",
    "\n",
    "# ...and linear algebra operations like determinant and singular value decomposition\n",
    "print('\\nDeterminant of r:')\n",
    "print(torch.det(r))\n",
    "print('\\nSingular value decomposition of r:')\n",
    "print(torch.svd(r))\n",
    "\n",
    "# ...and statistical and aggregate operations:\n",
    "print('\\nAverage and standard deviation of r:')\n",
    "print(torch.std_mean(r))\n",
    "print('\\nMaximum value of r:')\n",
    "print(torch.max(r))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfjoIDTyVvUp"
   },
   "source": [
    "Pay special attention to the shape of your tensors.\n",
    "NOTE: This code is supposed to be broken to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "error",
     "timestamp": 1729630324654,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "ZTfFFF_gV1Ki",
    "outputId": "35080890-014d-4e7d-d6ea-b9241c1b795c"
   },
   "source": [
    "ones = torch.ones(2, 3)\n",
    "print(ones)\n",
    "\n",
    "twos = torch.ones(2, 3) * 2 # every element is multiplied by 2\n",
    "print(twos)\n",
    "\n",
    "threes = ones + twos       # additon allowed because shapes are similar\n",
    "print(threes)              # tensors are added element-wise\n",
    "print(threes.shape)        # this has the same dimensions as input tensors\n",
    "\n",
    "r1 = torch.rand(2, 3)\n",
    "r2 = torch.rand(3, 2)\n",
    "r3 = r1 + r2               # error because shapes don't match!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFNJx-blXVze"
   },
   "source": [
    "## Build LaNet Digit Classifier in PyTorch\n",
    "\n",
    "One of the very first hand-written digit classifiers was called \"LaNet\".  [Learn more here](https://d2l.ai/chapter_convolutional-neural-networks/lenet.html)\n",
    "\n",
    "\n",
    "LeNet consists of two parts: (i) a convolutional encoder consisting of two convolutional layers; and (ii) a dense block consisting of three fully connected layers.\n",
    "\n",
    "\n",
    "![Alt text for broken image link](https://anatomiesofintelligence.github.io/img/l/lenet5-architecture.gif)\n",
    "\n",
    "\n",
    "Here's how it works. The first layer (C1) is a convolutional layer, meaning that it scans the input image for features it learned during training. It outputs a map of where it saw each of its learned features in the image.\n",
    "\n",
    "This \"activation map\" is downsampled in layer S2.\n",
    "\n",
    "Layer C3 is another convolutional layer, this time scanning C1's activation map for combinations of features. It also puts out an activation map describing the spatial locations of these feature combinations, which is downsampled in layer S4.\n",
    "\n",
    "Finally, the fully-connected layers at the end, F5, F6, and OUTPUT, are a classifier that takes the final activation map, and classifies it into one of ten bins representing the 10 digits.\n",
    "\n",
    "### Let' take a look in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1729630333683,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "bO0_iFkCZEnu"
   },
   "source": [
    "import torch                     # for all things PyTorch\n",
    "import torch.nn as nn            # for torch.nn.Module, the parent object for PyTorch models\n",
    "import torch.nn.functional as F  # for the activation function\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (B&W), 6 output channels, 3x3 convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxAuwO16Z6Z-"
   },
   "source": [
    "## Initialize our model (class)\n",
    "Instantiate the LeNet class, and we print the net object.\n",
    "\n",
    "A subclass of torch.nn.Module will report the layers it has created and their shapes and parameters. This can provide a handy overview of a model if you want to get the gist of its processing.\n",
    "\n",
    "## Make a fake image\n",
    "\n",
    "Next, we make a dummy input representing a 32x32 image with 1 color channel. Ordinarily we would use a real image. This data is random, so the classifier will choose the best match. Just don't expect an actual digit!\n",
    "\n",
    "We added an extra dimension to our tensor - the \"batch\" dimension. PyTorch models assume they are working on batches of data - for example, a batch of 16 of our image tiles would have the shape (16, 1, 32, 32). Since we're only using one image, we create a batch of 1 with shape (1, 1, 32, 32).\n",
    "\n",
    "## Make an Inference\n",
    "\n",
    "We ask the model for an inference by calling it like a function: net(input). The output of this call represents the model's confidence that the input represents a particular digit. (Since this instance of the model hasn't learned anything yet, we shouldn't expect to see any signal in the output.) Looking at the shape of output, we can see that it also has a batch dimension, the size of which should always match the input batch dimension. If we had passed in an input batch of 16 instances, output would have a shape of (16, 10).\n",
    "\n",
    "Let's try a run and see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1729630342956,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "K4ARhq_8Zrke",
    "outputId": "027fbf3e-c039-4db0-84b6-b2054a80d56f"
   },
   "source": [
    "net = LeNet()\n",
    "print(net)                         # what does the object tell us about itself?\n",
    "\n",
    "input = torch.rand(1, 1, 32, 32)   # stand-in for a 32x32 black & white image\n",
    "print('\\nImage batch shape:')\n",
    "print(input.shape)\n",
    "\n",
    "output = net(input)                # we don't call forward() directly\n",
    "print('\\nRaw output:')\n",
    "print(output)\n",
    "print(output.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErSmBWyNdaK0"
   },
   "source": [
    "## Building A Model\n",
    "\n",
    "For a real example, we'll load a dataset from TorchVision. This will give us the chance to use the DataLoader to feed the model batches of data. We typically break data up into chunks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 5321,
     "status": "ok",
     "timestamp": 1729630355516,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "qDDuWzdEdc8Q"
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1729630362556,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "vddME_SQdwkP"
   },
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Nk73o6d7Bp"
   },
   "source": [
    "### Here, we specify two input transformations:\n",
    "\n",
    "\n",
    "transforms.ToTensor() converts images loaded by Pillow into PyTorch tensors.\n",
    "\n",
    "transforms.Normalize() adjusts the values of the tensor so that their average is zero and their standard deviation is 0.5. Most activation functions have their strongest gradients around x = 0, so centering our data there can speed learning.\n",
    "There are many more transforms available, including cropping, centering, rotation, and reflection.\n",
    "\n",
    "## Now let's get some sample images...\n",
    "\n",
    "Next, we'll download and create an instance of the CIFAR10 dataset (it make take some time).  This are 32x32 color images of 10 classes of objects: 6 of animals (bird, cat, deer, dog, frog, horse) and 4 of vehicles (airplane, automobile, ship, truck). This is an example of creating a dataset object in PyTorch.\n",
    "\n",
    "Downloadable datasets (like CIFAR-10 above) are subclasses of torch.utils.data.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8219,
     "status": "ok",
     "timestamp": 1729630372815,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "ScY-OiALeAz-",
    "outputId": "9380bb5c-1003-42c3-fdeb-babf563258d7"
   },
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oeSjV3yeT2D"
   },
   "source": [
    "\n",
    "When we instantiate our dataset, we need to tell the system:\n",
    "\n",
    "* where we want data to go\n",
    "* whether to download the data\n",
    "* whether we're using data for training or or testing\n",
    "* what transformations to use\n",
    "\n",
    "Once your dataset is ready, you can give it to the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1729630381068,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "sDLUdIE6e2bO"
   },
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJT8opIMe3E7"
   },
   "source": [
    "## Key Points\n",
    "\n",
    "1. A Dataset subclass wraps access to the data, and is specialized to the type of data it's serving.\n",
    "\n",
    "2. The DataLoader knows nothing about the data, but organizes the input tensors served by the Dataset into batches with the parameters you specify.\n",
    "\n",
    "We've asked a DataLoader to give us batches of 4 images from trainset, randomizing their order (shuffle=True), and we told it to spin up two workers to load data from disk.  Let's visualize:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1729630384176,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "kYJG9XKYfE1_",
    "outputId": "0e241b74-9506-403f-c0b5-ad231805d64b"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "# Use next(dataiter) instead of dataiter.next()\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hG3-b6ngpUE"
   },
   "source": [
    "\n",
    "## Training your model\n",
    "\n",
    "Let's put it all together to load and test some images from our dataset..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1729630389053,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "nAvGIE0UguXB"
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim #a new lib...\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2451,
     "status": "ok",
     "timestamp": 1729630393592,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "M1lLrA0uhXei",
    "outputId": "f3f245f3-0c4b-46c4-f54d-e14fa8182b57"
   },
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 929,
     "status": "ok",
     "timestamp": 1729630396651,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "0y_Dh7LEhb39",
    "outputId": "21493a92-939c-4f56-ea48-1d42804c7f8b"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "# Use next(dataiter) instead of dataiter.next()\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKuefBDdhqnk"
   },
   "source": [
    "\n",
    "Ok...we have a dataset to train our model. Now lets make the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1729630405575,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "vrO8QZCOjEVy"
   },
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne7L9j_tipeX"
   },
   "source": [
    "Next we need to functions:\n",
    "1. a loss function\n",
    "2. a optimizer function\n",
    "\n",
    "The loss function, measures how far from our ideal output was the model's prediction.\n",
    "\n",
    "The optimizer is what drives the learning.This optimizer implements stochastic gradient descent, one of the more straightforward optimization algorithms.\n",
    "\n",
    "Besides parameters of the algorithm, like the learning rate (lr) and momentum, we also pass in net.parameters(), which is a collection of all the learning weights in the model - which is what the optimizer adjusts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1729630409606,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "nu82zQ9diW7S"
   },
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey-zUcqViXyT"
   },
   "source": [
    "Finally, all of this is assembled into the training loop.  We will do two iterations [range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228860,
     "status": "ok",
     "timestamp": 1729630640781,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "WV947XzthxEl",
    "outputId": "f1b7a0a8-13e9-4ff4-80a1-4514209d065f"
   },
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "larPHC6Vjf3j"
   },
   "source": [
    "Each pass has an inner loop that iterates over the training data (line 4), serving batches of transformed input images and their correct labels.\n",
    "\n",
    "Zeroing the gradients (line 9) is an important step. Gradients are accumulated over a batch; if we do not reset them for every batch, they will keep accumulating, which will provide incorrect gradient values, making learning impossible.\n",
    "\n",
    "In line 12, we ask the model for its predictions on this batch. In the following line (13), we compute the loss - the difference between outputs (the model prediction) and labels (the correct output).\n",
    "\n",
    "In line 14, we do the backward() pass, and calculate the gradients that will direct the learning.\n",
    "\n",
    "In line 15, the optimizer performs one learning step - it uses the gradients from the backward() call to nudge the learning weights in the direction it thinks will reduce the loss.\n",
    "\n",
    "The remainder of the loop does some light reporting on the epoch number, how many training instances have been completed, and what the collected loss is over the training loop.\n",
    "\n",
    "Take a look at the output of our test run. Note that the loss is monotonically descending, indicating that our model is continuing to improve its performance on the training dataset.\n",
    "\n",
    "As a final step, we should check that the model is actually doing *general* learning, and not simply \"memorizing\" the dataset. This is called **overfitting,** and usually indicates that the dataset is too small (not enough examples for general learning), or that the model has more learning parameters than it needs to correctly model the dataset.\n",
    "\n",
    "This is the reason datasets are split into training and test subsets - to test the generality of the model, we ask it to make predictions on data it hasn't trained on:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13091,
     "status": "ok",
     "timestamp": 1729630785402,
     "user": {
      "displayName": "rick gessner",
      "userId": "14732443016100277292"
     },
     "user_tz": 420
    },
    "id": "J-Yx0YE2j1cx",
    "outputId": "82864f0b-0a75-40e5-e170-7da2ca240cb2"
   },
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfQOs6tIj7q7"
   },
   "source": [
    "Running this, you should see that the model is roughly  > 53% accurate at this point. That's not exactly state-of-the-art, but it's far better than the 10% accuracy we'd expect from a random output, and proves our model is learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOySFKj311px6dCDcbxMOEK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
