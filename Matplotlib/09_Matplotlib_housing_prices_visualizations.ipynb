{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## About the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMES Housing Dataset by Dean De Cock (Link: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices visualizations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install pandas matplotlib seaborn numpy scikit-learn scipy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import os\n",
    "import requests\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "thePath = \"./\"\n",
    "theFile = 'train.csv'\n",
    "theLink = \"https://dse200.dev/Day3/train.csv\"\n",
    "\n",
    "if not os.path.exists(thePath + theFile):\n",
    "    r = requests.get(theLink)\n",
    "    with open(thePath + theFile, 'wb') as f:\n",
    "        f.write(r.content)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "- Visualize\n",
    "- Find Missing Data\n",
    "- Look For Correlations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df = pd.read_csv(thePath + 'train.csv') # loading the ames data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df['SalePrice'].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(df['SalePrice']);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the data\n",
    "- Deviates from the normal distribution.\n",
    "- Has appreciable positive skewness.\n",
    "- Shows peakedness."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(\"Skewness: %f\" % df['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df['SalePrice'].kurt())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Relations with Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "var = 'GrLivArea'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "var = 'TotalBsmtSF'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear relation with a higher slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of Relations with Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "var = 'OverallQual'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see a positive correlation between these two variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "var = 'YearBuilt'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);\n",
    "plt.xticks(rotation=90);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although not a strong one, we still see a positive correlation between these two variables as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "var = 'LotArea' # 'YearBuilt' \n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "#corrmat = df.corr()\n",
    "data = pd.concat([df['SalePrice'], df['LotFrontage'],df['YearBuilt'],df['LotArea']], axis=1)\n",
    "corrmat = data.corr()\n",
    "#f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this overview of all the realtions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We pick \"k\" columns which are most correlated with Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "k = 10 \n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cols"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "cmvals = df[cols].values.T\n",
    "cmvals"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'<br/>\n",
    "'GarageCars' can be assumed to be dependent on 'GarageArea'. Hence we choose only 'GarageCars' since its correlation with 'SalePrice' is higher <br/>\n",
    "'TotalBsmtSF' and '1stFloor' represent kinda the same thing so we pick one ('TotalBsmtSF')<br/>\n",
    "'TotRmsAbvGrd' and 'GrLivArea' have a high correlation as expected.<br/>\n",
    "TODO :  Time series analysis for 'YearBuilt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Feature Engineering for Housing Prices\n\nLet's engineer features to improve predictive performance! The Ames Housing dataset is rich with opportunities.\n\n**Why Feature Engineering Matters for Real Estate:**\n- **Age/depreciation:** Houses lose/gain value over time\n- **Size efficiency:** Price per square foot varies\n- **Quality combinations:** Quality Ã— Size interactions\n- **Neighborhood context:** Relative pricing matters",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(df[cols], size = 2.5)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns with more than 80% of the data is missing are chosen to be deleted. Hence the set of variables (e.g. 'PoolQC', 'MiscFeature', 'Alley', etc. are chosen for deletion. Further, these features show nearly 0 correlation with 'Sale Price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'GarageCars' will represent most info regarding garages, hence other 'GarageX' variables can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'Electrical', we can either use another value to fill the missing value or drop the observation. In this case we drop the observation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "(missing_data[missing_data['Total'] > 1]).index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "#df = df.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
    "#df = df.drop(df.loc[df['Electrical'].isnull()].index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "var = 'GrLivArea'\n",
    "data = pd.concat([df['SalePrice'], df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rightmost observations in 'GrLivArea' seem to be outliers <br/>\n",
    "The topmost observations in 'SalePrice' seem to follow the trend hence we do not consider them as outliers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df.sort_values(by = 'GrLivArea', ascending = False)[:2]\n",
    "df = df.drop(df[df['Id'] == 1299].index)\n",
    "df = df.drop(df[df['Id'] == 524].index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(df['SalePrice'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df['SalePrice'], plot=plt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Normal Probability Plot : </b>The data are plotted against a theoretical normal distribution in such a way that the points should form an approximate straight line. Departures from this straight line indicate departures from normality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in case of positive skewness, log transformations usually works well"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df['SalePrice'] = np.log(df['SalePrice'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replotting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(df['SalePrice'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df['SalePrice'], plot=plt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the col : GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(df['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df['GrLivArea'], plot=plt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying similar transformation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df['GrLivArea'] = np.log(df['GrLivArea'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(df['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df['GrLivArea'], plot=plt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for col : TotalBsmtSF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(df['TotalBsmtSF'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df['TotalBsmtSF'], plot=plt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see postive skewness but quite a few of the points are 0"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "df.loc[df['TotalBsmtSF']>0,'TotalBsmtSF'] = np.log(df['TotalBsmtSF'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "sns.distplot(df[df['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df[df['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "s = pd.Series(list('abca'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "s"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python <br/>\n",
    "https://www.kaggle.com/ekami66/detailed-exploratory-data-analysis-with-python/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### 1. Age and Remodeling Features\n\n**Justification:** Age affects value differently:\n- House age (years since built)\n- Years since remodel\n- Is newly built? (premium)\n- Never remodeled? (penalty)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Reload fresh data for feature engineering\ndf_fe = pd.read_csv(thePath + 'train.csv')\n\n# Current year (or use max year in dataset)\ncurrent_year = df_fe['YrSold'].max()\n\n# Age features\ndf_fe['house_age'] = current_year - df_fe['YearBuilt']\ndf_fe['years_since_remodel'] = current_year - df_fe['YearRemodAdd']\ndf_fe['is_newly_built'] = (df_fe['house_age'] <= 2).astype(int)\ndf_fe['never_remodeled'] = (df_fe['YearBuilt'] == df_fe['YearRemodAdd']).astype(int)\n\nprint(\"Age features created:\")\nprint(df_fe[['YearBuilt', 'YearRemodAdd', 'house_age', 'years_since_remodel', \n             'is_newly_built', 'never_remodeled']].head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "#### 2. Total Square Footage and Ratios\n\n**Justification:** Total living space and efficiency metrics:\n- Total square footage (above + basement)\n- Price per square foot (efficiency)\n- Lot coverage ratio (house size vs lot size)\n- Basement percentage",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Total square footage\ndf_fe['total_sqft'] = df_fe['GrLivArea'] + df_fe['TotalBsmtSF']\ndf_fe['total_bathrooms'] = df_fe['FullBath'] + 0.5 * df_fe['HalfBath']\ndf_fe['total_porch_sf'] = (df_fe['OpenPorchSF'] + df_fe['EnclosedPorch'] + \n                            df_fe['3SsnPorch'] + df_fe['ScreenPorch'])\n\n# Efficiency ratios\ndf_fe['basement_ratio'] = df_fe['TotalBsmtSF'] / (df_fe['total_sqft'] + 1)\ndf_fe['lot_coverage_ratio'] = df_fe['total_sqft'] / (df_fe['LotArea'] + 1)\n\n# Quality Ã— Size interaction\ndf_fe['quality_x_sqft'] = df_fe['OverallQual'] * df_fe['total_sqft']\n\nprint(\"Size and ratio features created:\")\nprint(df_fe[['GrLivArea', 'TotalBsmtSF', 'total_sqft', 'basement_ratio', \n             'lot_coverage_ratio', 'quality_x_sqft']].head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "#### 3. Neighborhood Context (Target Encoding)\n\n**Justification:** Neighborhood drives pricing:\n- Average sale price per neighborhood\n- Price relative to neighborhood\n- Neighborhood wealth indicators",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Neighborhood aggregations\nneighborhood_stats = df_fe.groupby('Neighborhood')['SalePrice'].agg(['mean', 'median', 'std']).reset_index()\nneighborhood_stats.columns = ['Neighborhood', 'neighborhood_avg_price', \n                               'neighborhood_median_price', 'neighborhood_price_std']\n\ndf_fe = df_fe.merge(neighborhood_stats, on='Neighborhood', how='left')\n\n# Relative pricing\ndf_fe['price_vs_neighborhood'] = df_fe['SalePrice'] / (df_fe['neighborhood_avg_price'] + 1)\n\n# Wealthy neighborhood indicator\ndf_fe['is_wealthy_neighborhood'] = (df_fe['neighborhood_avg_price'] > \n                                     df_fe['neighborhood_avg_price'].quantile(0.75)).astype(int)\n\nprint(\"Neighborhood features created:\")\nprint(df_fe[['Neighborhood', 'SalePrice', 'neighborhood_avg_price', \n             'price_vs_neighborhood', 'is_wealthy_neighborhood']].head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "#### 4. Quality and Condition Scores\n\n**Justification:** Combine quality/condition ratings:\n- Overall quality score (quality + condition)\n- Has garage (binary)\n- Has basement (binary)\n- Has fireplace, pool, etc.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Combined quality score\ndf_fe['total_quality_score'] = df_fe['OverallQual'] + df_fe['OverallCond']\n\n# Binary amenity features\ndf_fe['has_garage'] = (df_fe['GarageArea'] > 0).astype(int)\ndf_fe['has_basement'] = (df_fe['TotalBsmtSF'] > 0).astype(int)\ndf_fe['has_fireplace'] = (df_fe['Fireplaces'] > 0).astype(int)\ndf_fe['has_pool'] = (df_fe['PoolArea'] > 0).astype(int)\ndf_fe['has_2nd_floor'] = (df_fe['2ndFlrSF'] > 0).astype(int)\n\n# High-end features count\ndf_fe['luxury_features_count'] = (\n    df_fe['has_pool'] + \n    df_fe['has_fireplace'] + \n    (df_fe['OverallQual'] >= 8).astype(int) +\n    (df_fe['GarageCars'] >= 3).astype(int)\n)\n\nprint(\"Quality and amenity features created:\")\nprint(df_fe[['OverallQual', 'OverallCond', 'total_quality_score', 'has_garage', \n             'has_fireplace', 'luxury_features_count']].head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Summary: Housing Price Feature Engineering\n\n| Feature Type | Examples | Impact | Insight |\n|-------------|----------|--------|---------|\n| **Age** | house_age, years_since_remodel | High | Depreciation matters |\n| **Size/Ratios** | total_sqft, qualityÃ—sqft | Very High | Interactions boost value |\n| **Neighborhood** | Avg price, relative pricing | Very High | Location, location, location |\n| **Quality/Amenities** | Quality scores, luxury count | High | Premium features add value |\n\n**Key Observations:**\n- The notebook already identified top correlations (OverallQual, GrLivArea, etc.)\n- Our features ADD context and interactions\n- Target encoding (neighborhood averages) is powerful but watch for overfitting!\n\nNow these engineered features are ready for modeling!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Feature count summary\nprint(f\"Original features: {df.shape[1]}\")\nprint(f\"After feature engineering: {df_fe.shape[1]}\")\nprint(f\"New features created: {df_fe.shape[1] - df.shape[1]}\")\nprint(f\"\\nSample of new features:\")\nnew_features = [col for col in df_fe.columns if col not in df.columns]\nprint(new_features)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
