{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Data Analysis and Machine Learning Tasks\n",
    "\n",
    "## Setup\n",
    "First, let's import the necessary libraries and load our data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install pandas numpy matplotlib seaborn scikit-learn requests",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# if we can import the drive module, we are running on colab\n",
    "thePath = \"./\"  # Adjust this path as necessary\n",
    "link = \"https://dse200.dev/Day3/airbnb_sd_listings.csv\"\n",
    "file = \"airbnb_sd_listings.csv\"\n",
    "\n",
    "if not os.path.exists(thePath + file):\n",
    "    r = requests.get(link)\n",
    "    with open(thePath + file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(thePath + file)\n",
    "\n",
    "# Display the first few rows and data info\n",
    "print(data.head())\n",
    "print(data.info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Analysis and Visualization\n",
    "\n",
    "a) Create a bar plot showing the average price for each room_type.\n",
    "\n",
    "b) What is the most expensive room_type on average?\n",
    "\n",
    "c) Create a scatter plot of price vs. number_of_reviews. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Price with Linear Regression\n",
    "\n",
    "We'll create a machine learning model to predict the price of a listing.\n",
    "\n",
    "a) Prepare the data for machine learning:\n",
    "   - Select relevant features (you decide which ones to use)\n",
    "   - Handle any categorical variables\n",
    "   - Split the data into training and testing sets\n",
    "\n",
    "b) Create and train linear regression model.\n",
    "\n",
    "c) Evaluate linear regression model using Mean Squared Error and R-squared score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Select relevant features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Linear Regression\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Price with Random Forest Regressor\n",
    "\n",
    "We'll create a machine learning model to predict the price of a listing.\n",
    "\n",
    "a) Create and train Random Forest Regressor.\n",
    "\n",
    "c) Evaluate model using Mean Squared Error and R-squared score."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## Your code here\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Models and using best model to predict price\n",
    "\n",
    "a) Which model performs better? Why do you think this is the case?\n",
    "\n",
    "b) How did the speed of the models compare?\n",
    "\n",
    "c) Use your best model to predict the price for a new listing with these features:\n",
    "   - room_type: 'Entire home/apt'\n",
    "   - minimum_nights: 2\n",
    "   - number_of_reviews: 50\n",
    "   - availability_365: 200\n",
    "   - neighbourhood: 'Pacific Beach'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Visualization and Comparison\n",
    "\n",
    "a) Create a heatmap showing the correlation between numerical features in the dataset.\n",
    "\n",
    "b) Using the Random Forest model from Task 8, plot the feature importances. Which features are most important for predicting price?\n",
    "\n",
    "c) Create a box plot showing the distribution of prices for each neighbourhood. What do you observe about price variations across neighbourhoods?\n",
    "\n",
    "d) Based on your analysis, what recommendations would you give to someone looking to list their property on this platform to maximize their potential earnings?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## Your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Feature Engineering: Creating Better Predictors\n\nFeature engineering is the process of creating new features from existing data to improve model performance. Let's progressively build more sophisticated features from our Airbnb dataset.\n\n### Why Feature Engineering Matters\nRaw data rarely contains all the patterns models need. By creating new features, we can:\n- Capture non-linear relationships\n- Encode domain knowledge\n- Create interaction effects between variables\n- Extract signal from text and temporal data\n\nLet's start simple and progressively get more advanced.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Temporal Features\n",
    "\n",
    "**Justification:** The `last_review` date contains hidden information:\n",
    "- How recent is the activity? Recent reviews suggest active, popular listings\n",
    "- Seasonality patterns (month, quarter) affect pricing\n",
    "- Inactive listings might be priced differently\n",
    "\n",
    "These features capture time-based patterns that affect demand and pricing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Make a copy for feature engineering\ndata_fe = data.copy()\n\n# Convert to datetime\ndata_fe['last_review'] = pd.to_datetime(data_fe['last_review'])\n\n# Extract temporal features\ndata_fe['days_since_last_review'] = (pd.Timestamp.now() - data_fe['last_review']).dt.days\ndata_fe['last_review_year'] = data_fe['last_review'].dt.year\ndata_fe['last_review_month'] = data_fe['last_review'].dt.month\ndata_fe['last_review_quarter'] = data_fe['last_review'].dt.quarter\ndata_fe['is_recently_reviewed'] = (data_fe['days_since_last_review'] < 30).astype(int)\n\nprint(\"Temporal features created:\")\nprint(data_fe[['last_review', 'days_since_last_review', 'last_review_month', \n               'last_review_quarter', 'is_recently_reviewed']].head(10))",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Geographic Features\n",
    "\n",
    "**Justification:** Location is crucial for Airbnb pricing:\n",
    "- Distance to downtown/attractions affects desirability\n",
    "- Proximity to coast/beach in San Diego commands premium pricing\n",
    "- Spatial clustering reveals neighborhood quality\n",
    "\n",
    "Geographic features encode location value beyond just neighborhood names."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Distance from San Diego downtown (32.7157° N, 117.1611° W)\nfrom math import radians, sin, cos, sqrt, atan2\n\ndef haversine_distance(lat1, lon1, lat2=32.7157, lon2=-117.1611):\n    \"\"\"Calculate distance in km between two lat/lon points\"\"\"\n    R = 6371  # Earth radius in km\n    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    return 2 * R * atan2(sqrt(a), sqrt(1-a))\n\ndata_fe['distance_to_downtown'] = data_fe.apply(\n    lambda x: haversine_distance(x['latitude'], x['longitude']), axis=1\n)\n\n# Coastal proximity (approximate - more negative longitude = closer to ocean)\ndata_fe['distance_to_coast'] = abs(data_fe['longitude'] + 117.25)\n\nprint(\"Geographic features created:\")\nprint(data_fe[['neighbourhood', 'latitude', 'longitude', \n               'distance_to_downtown', 'distance_to_coast']].head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Ratio and Interaction Features\n",
    "\n",
    "**Justification:** Ratios reveal efficiency and engagement:\n",
    "- `review_rate`: How many reviews per available day? Shows booking frequency\n",
    "- `reviews_per_listing`: Distributes attention across host's portfolio\n",
    "- `price_per_min_night`: Normalizes price by minimum stay requirements\n",
    "- `is_professional_host`: Professional hosts may price differently\n",
    "\n",
    "These capture relationships between variables that models might miss."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Review engagement metrics\ndata_fe['review_rate'] = data_fe['number_of_reviews'] / (data_fe['availability_365'] + 1)\ndata_fe['reviews_per_listing'] = data_fe['number_of_reviews'] / (data_fe['calculated_host_listings_count'] + 1)\n\n# Price-related ratios\ndata_fe['price_per_min_night'] = data_fe['price'] / (data_fe['minimum_nights'] + 1)\n\n# Host categorization\ndata_fe['is_professional_host'] = (data_fe['calculated_host_listings_count'] > 2).astype(int)\n\nprint(\"Ratio/interaction features created:\")\nprint(data_fe[['number_of_reviews', 'availability_365', 'review_rate', \n               'reviews_per_listing', 'is_professional_host']].head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Aggregated Neighborhood Features\n",
    "\n",
    "**Justification:** Neighborhood context matters:\n",
    "- Individual listing price means little without local market context\n",
    "- Neighborhood statistics capture area desirability and market dynamics\n",
    "- `price_vs_neighborhood`: Is this listing priced above/below local average?\n",
    "\n",
    "This is **target encoding** - using aggregate target statistics as features (be careful of leakage!)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate neighborhood statistics\nneighborhood_stats = data_fe.groupby('neighbourhood').agg({\n    'price': ['mean', 'median', 'std'],\n    'number_of_reviews': 'mean',\n    'availability_365': 'mean'\n}).reset_index()\n\n# Flatten column names\nneighborhood_stats.columns = ['neighbourhood', 'neighborhood_avg_price', \n                               'neighborhood_median_price', 'neighborhood_price_std',\n                               'neighborhood_avg_reviews', 'neighborhood_avg_availability']\n\n# Merge back to main dataset\ndata_fe = data_fe.merge(neighborhood_stats, on='neighbourhood', how='left')\n\n# Relative pricing feature\ndata_fe['price_vs_neighborhood'] = data_fe['price'] / (data_fe['neighborhood_avg_price'] + 1)\n\nprint(\"Neighborhood aggregated features created:\")\nprint(data_fe[['neighbourhood', 'price', 'neighborhood_avg_price', \n               'neighborhood_median_price', 'price_vs_neighborhood']].head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Natural Language Processing (NLP) Features\n",
    "\n",
    "**Justification:** The listing `name` contains marketing signals:\n",
    "- Keywords like \"luxury\", \"beach\", \"ocean\" signal premium listings\n",
    "- Text length/complexity may correlate with professionalism\n",
    "- Certain words indicate amenities (pool, parking, wifi)\n",
    "- Writing style (exclamation marks, uppercase) shows listing effort\n",
    "\n",
    "**Simple approach:** Keyword matching and basic statistics  \n",
    "**Advanced approach:** TF-IDF to find discriminative words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Basic text features\ndata_fe['name_length'] = data_fe['name'].str.len()\ndata_fe['name_word_count'] = data_fe['name'].str.split().str.len()\n\n# Keyword indicators (domain knowledge!)\ndata_fe['has_luxury_words'] = data_fe['name'].str.lower().str.contains(\n    'luxury|stunning|beautiful|amazing|gorgeous', na=False\n).astype(int)\n\ndata_fe['has_location_words'] = data_fe['name'].str.lower().str.contains(\n    'beach|ocean|downtown|view|bay', na=False\n).astype(int)\n\ndata_fe['has_amenity_words'] = data_fe['name'].str.lower().str.contains(\n    'pool|parking|wifi|kitchen|patio', na=False\n).astype(int)\n\n# Style indicators\ndata_fe['has_exclamation'] = data_fe['name'].str.contains('!', na=False).astype(int)\ndata_fe['is_uppercase'] = data_fe['name'].str.isupper().astype(int)\n\nprint(\"NLP features created:\")\nprint(data_fe[['name', 'name_length', 'name_word_count', 'has_luxury_words', \n               'has_location_words', 'has_amenity_words']].head(10))",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "#### Advanced NLP: TF-IDF Features\n\n**TF-IDF (Term Frequency-Inverse Document Frequency)** identifies words that are distinctive for certain listings. Words that appear frequently in one listing but rarely across all listings get high scores.\n\nThis is more sophisticated than simple keyword matching - it discovers patterns automatically.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Create TF-IDF features from listing names\ntfidf = TfidfVectorizer(max_features=20, stop_words='english', min_df=5)\ntfidf_features = tfidf.fit_transform(data_fe['name'].fillna(''))\n\n# Convert to DataFrame\ntfidf_df = pd.DataFrame(\n    tfidf_features.toarray(), \n    columns=[f'tfidf_{word}' for word in tfidf.get_feature_names_out()]\n)\n\n# Add to main dataset\ndata_fe = pd.concat([data_fe.reset_index(drop=True), tfidf_df], axis=1)\n\nprint(f\"TF-IDF features created: {tfidf_df.shape[1]} features\")\nprint(\"\\nTop TF-IDF words found:\")\nprint(list(tfidf.get_feature_names_out()))",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Binning and Categorization\n",
    "\n",
    "**Justification:** Sometimes continuous variables work better as categories:\n",
    "- Non-linear price relationships: A $50 → $100 increase matters more than $500 → $550\n",
    "- Binning can capture threshold effects (e.g., listings >180 days available may be different)\n",
    "- Helps models learn patterns within ranges\n",
    "\n",
    "This creates discrete buckets from continuous features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Price categories\ndata_fe['price_category'] = pd.cut(\n    data_fe['price'], \n    bins=[0, 100, 200, 500, 10000], \n    labels=['budget', 'moderate', 'expensive', 'luxury']\n)\n\n# Availability categories\ndata_fe['availability_category'] = pd.cut(\n    data_fe['availability_365'], \n    bins=[0, 90, 180, 270, 365],\n    labels=['low', 'medium', 'high', 'very_high']\n)\n\n# Review volume categories\ndata_fe['review_volume'] = pd.cut(\n    data_fe['number_of_reviews'],\n    bins=[0, 10, 50, 200, 1000],\n    labels=['new', 'established', 'popular', 'very_popular']\n)\n\nprint(\"Categorization features created:\")\nprint(data_fe[['price', 'price_category', 'availability_365', \n               'availability_category', 'number_of_reviews', 'review_volume']].head(10))",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Missing Value Indicators\n",
    "\n",
    "**Justification:** Missing values contain information:\n",
    "- Listings with no reviews might be new (different pricing strategy)\n",
    "- Missing `reviews_per_month` indicates no activity (not truly \"missing\")\n",
    "- The *presence* of missing data can be predictive\n",
    "\n",
    "Always create indicator variables for missingness patterns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Missing value indicators\ndata_fe['has_reviews'] = (~data_fe['last_review'].isna()).astype(int)\ndata_fe['missing_reviews_per_month'] = data_fe['reviews_per_month'].isna().astype(int)\ndata_fe['missing_host_name'] = data_fe['host_name'].isna().astype(int)\n\nprint(\"Missing value indicators created:\")\nprint(data_fe[['last_review', 'has_reviews', 'reviews_per_month', \n               'missing_reviews_per_month']].head(10))",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Summary: Feature Engineering Complete!\n\nWe've created **50+ new features** from just 18 original columns:\n\n| Category | Features | Difficulty | Key Insight |\n|----------|----------|------------|-------------|\n| **Temporal** | 5 features | Easy | Extract time patterns from dates |\n| **Geographic** | 2 features | Medium | Location drives pricing |\n| **Ratios** | 4 features | Medium | Relationships between variables matter |\n| **Aggregates** | 5 features | Advanced | Neighborhood context is crucial |\n| **NLP (Simple)** | 7 features | Advanced | Text contains marketing signals |\n| **NLP (TF-IDF)** | 20 features | Advanced | Auto-discover important words |\n| **Binning** | 3 features | Medium | Categories capture non-linearity |\n| **Missing** | 3 features | Easy | Missingness is informative |\n\n### Next Steps: Compare Model Performance\n\nNow let's see if these engineered features improve model accuracy!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Display final feature count\nprint(f\"Original columns: {data.shape[1]}\")\nprint(f\"After feature engineering: {data_fe.shape[1]}\")\nprint(f\"New features created: {data_fe.shape[1] - data.shape[1]}\")\nprint(f\"\\nSample of engineered features:\")\nprint(data_fe.columns.tolist()[-20:])",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
